\documentclass[main.tex]{subfiles}

\begin{document}

\section{Related Work}
Apart from the work at the Global Brain Institute, the most extensive collection of work deals with kidney exchanges. Next there are articles and theses in various fields studying barter exchange networks.

\subsection{Kidney Exchange}
There has been extensive research for kidney exchanges by computer scientists \cite{Bir}\cite{Abr1}, econmists \cite{Rot1}\cite{Rot2}, and doctors \cite{Seg1}. Kidneys are illegal to buy and sell with the exception of Iran \cite{Rot3}. At least a third of patients with \textit{willing} donors cannot get a transplant because of blood type incompatibility or positive crossmatch \cite{Seg1} \footnote{A crossmtach test involves mixing cells and serum to detremine if the patient will reject the donor's kidney.}. Thus starting in the early 21st century, incompatible donors and kidneys have been paired up and entered into national kidney exchanges.

In the offer network terminology, there are four task types: A, B, AB, O, and each user enters an ORpair: (donor type, patient type). Due to the limited number of types, Roth, Sonmez, and Unver \cite{Rot2} show that the maximal matching can be obtained with only up to 4-way exchanges \footnote{With the exception of tissue type incompatibilities / positve crossmatches.} \footnote{Using a general result that the size of matching needed is bounded by the number of types being exchanged.} in a thick market; moreover, the only benefit to 4-way exchanges are bounded by the number of rare (O, AB) ORpairs. This is good, as one distinguishing feature of kidney exchanges compared to general offer networks, other than having only four task types, is that an exchange of size $k$ requires $2k$ simultaneous surgeries. Chains can be done sequentially, passing along a donation, to enable 51+ transplants \cite{art:uab}. As the donation is passed along, there is no need for simultaneous surgeries. Another distinguishing feature of kidney exchange: finding the optimal solution is very important as every patient fewer is a potential death. With four task types and tens of thousands of users, the graphs are very dense.

Roth \cite{Rot2} uses patient distributions from U.S. Organ Procurement and Transplantation Network (OPTN) and the Scientific Registry of Transplant Recipients (SRTR) data to randomly generate populations of size 25, 50, and 100. Roth finds, in agreement with the theoretical results, that 4-way (or unbounded) exchanges do not provide much advantage over 2\&3-way exchanges.

Prior to this Roth, Somnez, and Unver investigated TTCC (Top Trading Cycle with Chains), an extension of Galel and Shapley's TTC (Top Trading Cycle) algorithm for housing exchange, for kidney exchange \cite{Rot1}. In TTC, each (donor, patient) pair has a list of most compatible kidneys, and points to the top of the list. Cycles are found, matched, and the ORpairs removed; then the poitners for remaining ORpairs are readjusted. These steps are repeated until there are no more cycles. In TTCC a cadaver queue is used to enhance the exchange: a donor who donates a kidney to the waitlist gets a priority position in the queue. This allows chain formation ending in an ORpair willing to accept a good queue position, which is still a lottery. The chain-selection rule of starting with the highest priority pair and keeping the chain (in case it grows in later rounds) results in a pareto optimal and strategy proof matching \footnote{That is, no other matching is strictly better for an ORpair without being worse for another, and lying about preferences does not confer any advantage.}. Roth experimented with simulations of population size 30, 100, and 300, finding TTCC does help. However, the longest cycles were of length 26, and chains of length 15.

Bir\'{o}, Manlove, and Rizzi in \textit{Maximum Weight Cycle Packing in Directed Graphs,
with Application to Kidney Exchange Programs} \cite{Bir} study the kidney exchange problem from a computer science perspective. Formally, the problem is to compute a \textbf{cycle packing of maximum size or weight}. The problem of finding the maximum with only 2\&3-cycles is APX-complete \footnote{And thus NP-complete.}. This result also applies to (<k)-cycles for $k > 2$, cycles of any bounded length, and to maximum cycle packings based on cycle weight. The case of 2-cycles and maximum cycle packings based on edge-weight alone have polynomial time solutions. Bir\'{o} describe, but don't use, a $(k - 1 + \epsilon)$-approximation algorithm using augmenting path search, and an exact algorithm that runs in $\bO^*(2^s)$ \footnote{Parametrized complexity: $\bO^*(2^s) = \bO(2^sf(n))$ where $f(n)$ is a polynomial in the input size, $n$.} where $s < |edges|/2$ is the size of a set, $S$ that covers at least one edge from each 3-cycle in the graph. The algorithm uses maximum matching on a graph constructed using subsets of $S$, thus the exponential.

Bir\'{o} use their exact algorithm to exchange kidneys with NHS Blood and Transplant (NHSBT) in the UK. The ($\leq 3$)-exchanges performed twice as well as the 2-exchanges, and $0.79$ that of the unbounded exchanges. In practice, NHSBT chose to use the $\leq 3$-exchanges as a reference while choosing a slightly smaller exchange with more 2-exchanges to diminish complications and the chance of the kidney exchange not happening for some reason.

Abraham, Blum, and Sandholm \cite{Abr1} develop an algorithm based on integer linear programming (ILP) that is used by the \textit{Alliance for Paired Donations}, a leading kidney exchange in the US. Non-incremental ILP methods can easily have billions of constraints and run out of memory, as either the variable or constraint number is exponential in input size. Thus Abraham use incremental problem formulation methods: constraint generation and column generation. Abraham finds column generation with a cycle-based ILP formulation to provide optimal exchanges fast enough for use with over 10,000 patients. In the branch and price method used a depth first search is used to look for positive price cycles. A further advantage of ILP is that additional features are easy to add as constraints.

Anderson et. al \cite{And3} develop an efficient constraint generation approach modeled on the prize-collecting traveling salesman praoblem (TSP) that also handles chains well.

Glorie, Klundert, and Wagelman \cite{Glo1} improve upon Abraham \cite{Abr1} by transforming the positive cycle search into one for negative cycles and then uset he Bellman-Ford algorithm to find them in PTIME instead of exponential time in the cycle or chain size limit.

Plaut, Dickerson, and Sandholm \cite{Pla} notice an error in Glorie's algorithm \cite{Glo1} in not handling loops in the Bellman-Ford algorithm properly. Fixing this adds a factor of $K$ (the chain size limit)\footnote{Apparently Dickerson has found an error in this fix for chains and in his PhD thesis \cite{Dick} proves that deciding whether a negative chain exists or not is NP-complete. See: \url{http://jpdickerson.com/pubs/plaut16hardness.pdf}}. This algorithm significantly outperforms the previous state-of-the-art methods, with the exception of Anderson's TSP approach \cite{And3} on unbounded chains, which are less likely to be fully realized in practice. An interesting point to note is that the algorithm performs significantly better with more altruistic donors.

Jia, Tang, Wang, and Zhang \cite{Jia1} prove the existence of PTIME approximation algorithms for up to ($ k$)-way exchanges based on the k-SET-PACKING problem. They test a local search approach as in \cite{Abb1}. One heuristic to initialise the local search is to greedily add cycles from vertices in sorted order. One ordering is Product of Degrees\footnote{$(d_{in}(v) + 1)*(d_{out}(v) + 1)$}, like Maximal \cite{Abb1}. The other ordering is to solve an LP relaxation and use the resulting variables. The local search achieves $90\%$ of the optimal performance under all settings, and $98\%+$ with the LP relaxation heuristic using only a small sample of the 3-cycles in the graph. Chains are dealt with greedily before running the cycle cover algorithms.

Over the course of his PhD, \textit{A Unified Approach to Dynamic Matching and Barter Exchange}, John P. Dickerson \cite{Dick} does an impressive amount of innovative research. Theoretically, there is a high probability an optimal matching whith cycle and chain length capped at 3 in a dense graph; moreover, long chains do not add much benefit due to the probability of rejection due to positive crossmatch testing. Position-indexed formulations (PICEF) for kidney exchange \cite{Dick} \cite{Dick1} are developed that perform reliably faster than other models in practice; alas, the linear programming relaxation is less tight. Smaller representations of the kidney compatibility graph allow for an PTIME algorithm\footnote{The algorithm is exponential in number of types, but that is fixed in kidney exchange.}, as well as allowing for SAT methods to be used \cite{Dick} \cite{Dick2}. In a static model, multiple rounds of rematching rejected cyles results in $75\%$+ more matches.

One topic in \cite{Dick} failure-aware matching: clearing the market while taking failure probability $p_{u,v}$ into account; however to solve the pricing problem in PTIME, failure probability must be assumed uniform. Accounting for $p$ with high probability gives a matching with linearly higher expected value than the maximum cardinality matching \cite{Dick} \cite{Dick3}. Bimodal matching with $p_{low}$ and $p_{high}$ worked significantly better than only $p_{avg}$. Edge-weights to prioritize hard-to-match highly sensitized patients for fairness to prevent marginalization works and does not decrease overall performance much. Pre-testing a random sample of edges for compatibility also significantly improves performance.

Another topic in \cite{Dick} is less myopic dynamic matching\footnote{Like greedy algorithms with respect to a dynamic model. Myopic optimization does the best possible in the current time step ignoring future time steps.} by learning vertex/edge/cycle/graph potentials. Thus, for example, a chain of 2 patients may be held back in one round due to its potential to form a 3-cycle in the next round. SMAC (sequential model-based optimization for general algorithm configuration) \cite{Hut1} is used to determine potentials. $10-20\%$ gain seems achievable.

Finally, Dickerson \cite{Dick} \cite{Dick4} look at multi-organ exchange. There are far fewer lung-donors; however a combined market causes a linear increase in the number of exchanges due to altruistic "chains that thread through the liver pool."

\subsubsection{Offer Network}

In \textit{A Dynamic Model of Barter Exchange}, Anderson, Ashlagi, Gamarnik, and Kanoria \cite{And1} investigate when exchanges should be performed in an offer network \footnote{barter exchange} with 2-way, 2\&3-way, and chain based matching. A \textbf{chain} is a match started by a gift, which Anderson calls the \textbf{head}. The chain ends when a user whose ORpair receives a gift has no-one to pass the gift on to; this user then becomes the \textbf{bridge} to initiate a chain in a new timestep. An Erdos-Renyi graph model \cite{Erdos} is used with probaiblity $p$ of an edge between any two nodes. Unlike in this thesis, each user has a unique task, so a task is removed once it is matched.

The experiments use a simulation with 16,000 arriving nodes, $p \in [0.04, 0.1]$, and for batche sizes $2^m$ for $m \in [0,6]$. Anderson finds experimentally and theoretically  that greedy matching is optimal, i.e., match cycles/chains as soon as they are found.

The average waiting times are:
\begin{center}
  \begin{tabular}{| l | l |}
    \hline
    2-way    & $\ln(2)/p^2 + o(1/p^2)$ \\
    2\&3-way & $\bO(1/p^{3/2})$ \\
    k-way (hypothesized) & $\bO(1/p^{\frac{k}{k-1}})$ \\
    chains   & $\bO(1/p)$ \\
    \hline
  \end{tabular}
\end{center}

An exception to the result in Anderson \cite{And1} is found in \textit{Matching Market Design} by Akbarpour \cite{Akb1}: if users take ORpairs off the market and the time this will be done is known in advance, then a patient algorithm that waits until the time step before an ORpair is taken off the market to match it performs better than a greedy algorithm. On the other hand, if the time the ORpair leaves the market is unknown, greedy performs better.

In \textit{On Efficient Recommendations for Online Exchange Markets}, Abbassi and Lakshmanan \cite{Abb1} perform experiments similar to those in this thesis. Abbassi uses a model where each user has an \textbf{item list} and a \textbf{wish list} and the system tries to recommend the maximum exchange, assuming the user is willing to ecxhange any wish list item for any possessed item \footnote{If each user has one item and wishes for one item, then Abbasi's model is the same as in this thesis.} A probabilistic model that can model user/item preferences or reputation is also analyzed, but not experimented with. The model is scale free with respect to item popularity, with slight deviation in wish list and item list popularity. Three algorithms are experimented with:

\begin{itemize}
  \item Maximal: find a greedy edge-disjoint cycle cover $M$ times, and use the one with maximum weight.
  \item Greedy: Greedily add cycle with largest weight.
  \item Local Search: For each cycle, check if adding it (possibly displacing some cycles) increases the cover weight.
\end{itemize}

Performance is measured in \textbf{coverage}, how many items are exchanged. Maximal performs almost as well as the slower algorithms\footnote{Let $V$ be the vertices, $E$ edges, and $\mathcal{B}$ the cycle cover. Then Maximal runs in $\bO((|V| + |E|)|\mathcal{B}|)$ and Greedy  in $\bO(|V|^{2k})$.}, and Abbassi finsd Maximal's performance increases significantly until $M \approx 100$.

Next, in \textit{Fair Recommendations for Online Barter Exchange Networks} Abassi, Lakshmanan, and Xie \cite{Abb2} test asynchronous exchange via a credit point system (modeled on Yahoo! Answers points more than money). Abassi find 50+ time slots are needed for synchronous exchanges as in \cite{Abb1} to facilitate as many transactions as the asynchronous model. This difference seems similar to that between the wait-time for (gift-headed) chains and and cycles in \cite{And1}, which also makes sense as all users start with an initial credit amount that can be used to get an item without giving an item, i.e., to get a gift\footnote{Investigation into the relation of initial credit distribution and effectiveness of the credit mechanism would be interesting.}. Four optimzation problems are formed: maximum value gained (based on credits), maximu cardinality exchange with maximum value gained, minimum transaction cost (in addition to the previous ones), and MAX-FAIR, maximum fairness, (minimizing the maximum credit gained by any user). All are PTIME computible except for MAX-FAIR. A greedy heuristic and an LP rounding heuristic are tested for MAX-FAIR: greedy achievse a factor of 2.3 to the optimum and the LP rounding achieves close performance. Abassi also obtains a data snapshot from \url{ReadItSwapIt.co.uk} and verify a scale free distribution of item popularity.

\subsubsection{Miscellaneous}

Fang, Tang, and Zuo study \textit{Digital Good Exchange} \cite{Fang} where, as with data, goods are not deplenished when exchanged but their value decreases. While in genreal, finding a non-trivial, PNE (pure nash equilibrium) is NP-complete, the problem can be solved in PTIME when agents have unit demand, i.e., request one other agent's data at a time (which may be reasonable in practice). The unit demand case fits into the basic offer network framework: (offer data $d_i$, request data $d_j$). An encouraging case for open data\footnote{The position that data should be freely available to everyone.} is that each agent asking for every other agent's data is a PNE weakly dominating all other strategies (except asking for nothing, complet secrecy).

Cooper and Garcia-Molina \cite{Coo1} design and test two protocol for trading data to replicate it; unlike in Fang \cite{Fang}, the more sites with the data the better. Their protocols focus on trading collection replication or trading deeds to data on their sites. The trading deeds algorithm reaches high global reliability faster. This service could perhaps be framed in an offer network framework.

Anagnostakis and Greenwald \cite{Ana1} teste exchange based methods for peer-to-peer file sharing as an alternative to two-way credit systems (upload and download). They get positvie results for up to 5-way exchanges. Exchanges are cycles detected by peers that maintain an incoming request tree (only up to depth 4). No effort is made to find optimal cycle covers in the decentralized system.

Cabinallas \cite{Cab0} \cite{Cab1} has done a lot of theoretical work on peer-to-peer bartering\footnote{decentralized bartering} in papers and his PhD thesis. Cabinallas compares 2-way, 2\&3-way, and optimal \footnote{via Munkres algorithm} exchanges. Cabinallas' primary focus is on distributed bartering via selfish agents without global knowledge. As in Abbassi \cite{Abb1} \cite{Abb2} agents have item and wish lists, but an Erdos-Renyi model is used for the item distribution. The level of satisfaction obtained over time in fully-connected to sparse graphs is tested: the market was found sterile when not the average degree was less than $11$. Kyle MacDonald, through a series of exchanges, traded a red paper clip for a house \footnote{http://oneredpaperclip.blogspot.dk/}. Cabinallas runs simulations to test whether this is possible in general when agents have personal valuations of items apart from a set market price: the answer is yes. The main use-case explored is distributed barter based directory services for use with DNS, community-based replication, or other content distribution networks to provide more scalability and reliability than server-based implementations. The model is a network of directory nodes clients can query (that may then query each other).


\end{document}
